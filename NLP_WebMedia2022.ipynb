{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <center>Processamento de Linguagem Natural em Textos de Mídias Sociais: Fundamentos, Ferramentas e Aplicações</center>\n",
    "\n",
    "### <center>XXVIII Simpósio Brasileiro de Sistemas Multimídia e Web (WebMedia 2022)</center>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<center>Frances A. Santos (UNICAMP), Jordan Kobellarz (UTFPR), Fábio R. de Souza (USP), Leandro A. Villas (UNICAMP), Thiago H. Silva (UTFPR)</center>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<center>Curitiba, PR</center>\n",
    "<center>07 de Novembro de 2022</center>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/webmedia2022-nlp/course-code/blob/main/NLP_WebMedia2022.ipynb\" target=\"_parent\"><img style=\"float: right;\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir no Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm #Instalando dependências específicas do spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "import pathlib\n",
    "import os \n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pathlib import Path\n",
    "\n",
    "# Criação do diretório \"data/\"\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from DataExtraction import DataExtraction\n",
    "from Preprocessing import Preprocessing\n",
    "from ModelosRepresentacao import ModelosEstatisticos, SentenceEmbeddings, WordEmbeddings\n",
    "from ExtracaoConhecimento import Clustering, SemanticComprehension, SentimentAnalysis\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download de arquivos usados por bibliotecas\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Introdução \n",
    "2. Texto de mídias sociais: suas principais características e como coletá-los\n",
    "3. Pré-processamento textual\n",
    "4. Representação de textos utilizando vetores numéricos\n",
    "5. Modelagem e extração de conhecimento\n",
    "6. Compreensão semântica e emocional\n",
    "7. Possíveis aplicações\n",
    "8. Perguntas & Respostas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# <center>1. Introdução</center>\n",
    "\n",
    "<img src=\"figs/social-media.jpeg\" style=\"float: center; zoom:100%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Mídias sociais são acessadas por aproximadamente 4,7 bilhões de usuários em todo o planeta (i.e., 59% da população) [Kemp 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exemplo (Twitter):\n",
    "\n",
    "* 200 Bilhões de postagens por ano\n",
    "* equivalente a 6 mil postagens por segundo\n",
    "\n",
    "Fonte: [Twitter Usage Statustics](https://www.internetlivestats.com/twitter-statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Possibilidades para acessar dados públicos em larga escala\n",
    "\n",
    "* **Twitter** - API (stream e histórico)\n",
    "* **Reddit** - API (stream e histórico)\n",
    "* **Meta (Instagram e Facebook)** - Plataforma CrowdTangle\n",
    "* **Swarm (Forsquare)** - API\n",
    "* **Flickr** - API\n",
    "* **Google Places** - API\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Aplicações na academia\n",
    "\n",
    "* análise de fenômenos sociais\n",
    "* sensoriamento social\n",
    "* detecção de notícias falsas\n",
    "* discurso de ódio\n",
    "* polarização política\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Aplicações na indústria\n",
    "\n",
    "* benchmarking (comparação com concorrentes)\n",
    "* forecasting (análise de tendências)\n",
    "* sistemas de recomendação\n",
    "* personalização / customização em larga escala\n",
    "* análise de risco\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# <center>2. Textos de mídias sociais</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Onde encontrar dados textuais?\n",
    "\n",
    "* postagens\n",
    "* artigos\n",
    "* mensagens / comentários\n",
    "* metainformações de páginas, imagens, videos, perfis, postagens, mensagens, etc. \n",
    "* extração de texto em imagem, áudio e video\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.1 Twitter\n",
    "\n",
    "* Mídia social de *Microblogging*\n",
    "* Mensagens limitadas a 280 caracteres\n",
    "* Uma das primeiras redes a disponibilizar uma API para extração de dados públicos em larga escala\n",
    "* Possibilidade de coleta de dados históricos ou em tempo real (*streaming*)\n",
    "* Qualquer dado público pode ser acessado, exceto os de perfis privados (menos de 10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Característica proeminente\n",
    "\n",
    "Simplicidade nas interações e dicionário de dados:\n",
    "\n",
    "* tweets\n",
    "* hashtags #\n",
    "* menções @\n",
    "* retweets RT\n",
    "* respostas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Dados que podem ser obtidos via API\n",
    "\n",
    "* **texto do tweet**\n",
    "* **timestamp**\n",
    "* **autor**\n",
    "    * nome\n",
    "    * localização\n",
    "    * se é verificado\n",
    "    * quantidade de seguidores, amigos, postagens\n",
    "    * data de criação da conta\n",
    "    * língua do perfil\n",
    "    * etc.\n",
    "* **geolocalização do tweet (GeoJson)**\n",
    "    * adicionada explícitamente\n",
    "    * ou capturada do dispositivo que gerou o tweet\n",
    "* **entidades**\n",
    "    * hashtags\n",
    "    * links\n",
    "    * menções\n",
    "    * mídias\n",
    "* **sinais sociais**\n",
    "    * quantidade de retweets\n",
    "    * quantidade de curtidas\n",
    "    * quantidade de respostas\n",
    "* etc. \n",
    "\n",
    "Conheça o [dicionário completo de dados de um tweet aqui](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exemplo de um tweet\n",
    "\n",
    "Alguns campos foram omitidos para facilitar a visualização. \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"created_at\": \"Thu Apr 06 15:24:15 +0000 2017\",\n",
    "  \"id_str\": \"850006245121695744\",\n",
    "  \"text\": \"1\\/ Today we\\u2019re sharing our vision for the future of the Twitter API platform!\\nhttps:\\/\\/t.co\\/XweGngmxlP\",\n",
    "  \"user\": {\n",
    "    \"id\": 2244994945,\n",
    "    \"name\": \"Twitter Dev\",\n",
    "    \"screen_name\": \"TwitterDev\",\n",
    "    \"location\": \"Internet\",\n",
    "    \"url\": \"https:\\/\\/dev.twitter.com\\/\",\n",
    "    \"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \\u2328\\ufe0f #TapIntoTwitter\"\n",
    "  },\n",
    "  \"place\": {   \n",
    "  },\n",
    "  \"entities\": {\n",
    "    \"hashtags\": [      \n",
    "    ],\n",
    "    \"urls\": [\n",
    "    ],\n",
    "    \"user_mentions\": [     \n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limitações e desafios\n",
    "\n",
    "* Limite de 280 caracteres\n",
    "    * restringe capacidade argumentativa\n",
    "    * usuários contornam com uso de contrações de palavras, gírias da internet e emojis\n",
    "* Representatividade da população\n",
    "    * pode não representar bem o usuário médio de internet\n",
    "    * [tendem a ser usadas por pessoas mais jovens, com maior renda e grau de escolaridade](https://blogs.oii.ox.ac.uk/policy/did-you-consider-twitters-lack-of-representativeness-before-doing-that-predictive-study/)\n",
    "* Representatividade do retorno da API\n",
    "    * a API de streaming se baseia na [**relevância** e não **completude** dos dados](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview)\n",
    "* Alta incidência de contas robô"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coletando Tweets\n",
    "\n",
    "- Utilizaremos a Twitter API v2 para coletar os tweets \n",
    "- Acesse a [página de desenvolverdores](https://developer.twitter.com/) e obtenha suas credenciais de acesso\n",
    "- Limitamos cada coleta a 10 tweets, mas todo o conteúdo dos tweets é adicionado (*appending*) ao arquivo local data/tweets.json\n",
    "- Além dos campos *id* e *text* que estão presentes nos tweets por padrão, também solicitamos os campos *created_at, entities, geo, lang, public_metrics, source*. Para ver a lista completa de campos possíveis, acesse esta [página](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet)\n",
    "- Filtramos para selecionar apenas os tweets escritos em Inglês ( *lang = \"en\"* ) e que contenham o termo \"nyc\", que referencia a cidade de Nova Iorque\n",
    "- Após coletar os tweets, extraímos os valores dos campos *text, timestamp_ms, ...* e retornamos no formato Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Credenciais da API do Twitter\n",
    "\n",
    "print(\"Informe seu 'API KEY'\")\n",
    "twitter_consumer_key = getpass.getpass()\n",
    "\n",
    "print(\"Informe seu 'API KEY SECRET'\")\n",
    "twitter_consumer_secret = getpass.getpass()\n",
    "\n",
    "print(\"Informe seu 'ACCESS TOKEN KEY'\")\n",
    "twitter_access_token_key = getpass.getpass()\n",
    "\n",
    "print(\"Informe seu 'ACCESS TOKEN SECRET'\")\n",
    "twitter_access_token_secret = getpass.getpass()\n",
    "\n",
    "print(\"Informe seu 'Bearer TOKEN'\")\n",
    "twitter_bearer_token = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Coleta de tweets\n",
    "df_tweets = DataExtraction().twitter(\n",
    "    twitter_consumer_key, \n",
    "    twitter_consumer_secret, \n",
    "    twitter_access_token_key, \n",
    "    twitter_access_token_secret, \n",
    "    twitter_bearer_token\n",
    ")\n",
    "\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Reddit\n",
    "\n",
    "* mídia social baseada em fóruns de discussão\n",
    "* comunidades/fóruns → \\subreddits\n",
    "* mais de 100K comunidades e 50 mi de usuários ativos diariamente em [2020](https://www.redditinc.com/advertising/audience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Características proeminentes\n",
    "\n",
    "* sistema de moderação autoorganizável\n",
    "    * \\subreddits possuem regras próprias criadas pelos moderadores e membros\n",
    "    * algumas comunidades possuem alto nível de comprometimento com as regras propostas\n",
    "    * mecanismos de recompensa para colaboradores ativos\n",
    "* possibilidade de coletar dados em stream e histórico\n",
    "    * vantagem de permitir a recuperação do histórico completo\n",
    "* permite acesso à qualquer informação disponível publicamente\n",
    "    * inclui postagens, comentários, perfis, comunidades e suas respectivas metainformações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Dados que podem ser obtidos via API\n",
    "\n",
    "**[submission (postagem)](https://praw.readthedocs.io/en/stable/code_overview/models/comment.html)**\n",
    "* id\n",
    "* url\n",
    "* permalink\n",
    "* created_utc\n",
    "* title\n",
    "* selftext (conteúdo da postagem)\n",
    "* score (número de upvotes)\n",
    "* [author](https://praw.readthedocs.io/en/stable/code_overview/models/comment.html) (Redditor)\n",
    "    * name\n",
    "    * created_utc\n",
    "    * comment_karma (pontuação do usuário)\n",
    "    * has_verified_email\n",
    "    * etc.\n",
    "* [comments](https://praw.readthedocs.io/en/stable/code_overview/models/comment.html) (árvore de comentários -- necessário percorrer com método específico para isso)\n",
    "    * author (Redditor)\n",
    "    * body\n",
    "    * distinguished\n",
    "    * etc.\n",
    "* distinguished (se a postagem foi destacada pelo moderador)\n",
    "* edited (se a postagem foi editada)\n",
    "* is_original_content (se foi marcada automaticamente como conteúdo original)\n",
    "* over_18 (se é conteúdo para maiores de 18 anos)\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limitações e desafios\n",
    "\n",
    "* a plataforma permite um alto grau de anonimidade\n",
    "    * é encorajado o uso de pseudônimo\n",
    "    * é possível fazer cadastro sem verificação\n",
    "    * abertura para comportamentos anti-éticos em comunidades não moderadas / permissivas\n",
    "* cada comunidade possui regras próprias\n",
    "    * práticas de moderação distintas\n",
    "    * dificultando a comparação \n",
    "* liberdade no formato\n",
    "    * campo aberto com possibiidade de uso de html e markdown\n",
    "* alta incidência de bots\n",
    "    * criam, fazem a curadoria e moderam conteúdos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coletando Posts de \\subreddits\n",
    "\n",
    "- Utilizaremos a [API do Reddit](https://www.reddit.com/dev/api) para coletar posts\n",
    "- Você deverá criar uma conta para acessar a API em [reddit.com](https://reddit.com)\n",
    "- Depois de criar a conta, obtenha os Client ID e o Client Secret\n",
    "- No exemplo a seguir, coletamos os top 100 posts de 5 subreddits, contendo o texto, url, número de comentários, data de criação e score (número de upvotes do post)\n",
    "- Os dados são salvos no arquivo local data/reddit_posts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Credenciais da API do Reddit\n",
    "\n",
    "print(\"Informe seu 'CLIENT ID'\")\n",
    "REDDIT_CLIENT_ID = getpass.getpass()\n",
    "\n",
    "print(\"Informe seu 'CLIENT SECRET'\")\n",
    "REDDIT_CLIENT_SECRET = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Subreddits com discussões sérias sobre assuntos como política, história e ciência.\n",
    "subreddits = [\n",
    "    'politics',\n",
    "    'AskHistorians',\n",
    "    'changemyview',\n",
    "    'COVID19',\n",
    "    'EverythingScience',\n",
    "    'science'\n",
    "]\n",
    "\n",
    "# Coleta os top 100 posts de cada Subreddit\n",
    "df_reddit_posts = DataExtraction().reddit(\n",
    "    REDDIT_CLIENT_ID,\n",
    "    REDDIT_CLIENT_SECRET,\n",
    "    subreddits=subreddits,\n",
    "    top_n=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Apresenta alguns posts com texto\n",
    "df_reddit_posts[df_reddit_posts['length'] > 0].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.3 Facebook (Meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Características proeminentes\n",
    "\n",
    "* alto grau de controle de privacidade\n",
    "* o anonimato é desencorajado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Formas de obter dados\n",
    "\n",
    "* via API nativa (limitada)\n",
    "* via web scraping (desencorajado)\n",
    "* via polls com usuários (não escalável)\n",
    "* via programa [Social Science One](https://socialscience.one/grant-process) (acesso direto à base do Facebook | difícil acesso | apenas para uso acadêmico)\n",
    "* via plataforma do [CrowdTangle](https://crowdtangle.com) (dados limitados a páginas e grupos famosos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### [CrowdTangle](https://crowdtangle.com)\n",
    "\n",
    "* iniciativa da Meta criada para jornalistas, agências de checagem de fatos, profissionais de marketing e pesquisadores\n",
    "* possibilidade de consultar e visualizar dados em tempo real pela interface (dashboards)\n",
    "* mesmos dados apresentados na interface podem ser obtidos via API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* informações que **podem** ser coletadas:\n",
    "     * quando algo foi postado\n",
    "     * tipo do post (video, imagem, texto)\n",
    "     * página, conta ou grupo onde o conteúdo foi postado\n",
    "     * quantidade de interações (likes, reações, comentários, compartilhamentos, visualizações de videos)\n",
    "     * páginas públicas ou contas que compartilharam o conteúdo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* informações que **não podem** ser coletadas:\n",
    "    * alcance ou impressões de um post\n",
    "    * conteúdos efêmeros, como stories, por exemplo\n",
    "    * informações demográficas de usuários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* a base de dados disponível se limita a:\n",
    "    * contas famosas (aprox. ~7 mi de páginas, grupos ou perfis verificados em 08/06/2021), incluindo:\n",
    "        * páginas públicas com mais de 50K curtidas\n",
    "        * grupos públicos com mais de 95K membros\n",
    "        * grupos públicos dos Estados Unidos com mais de 2K membros\n",
    "        * todos os perfis verificados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exemplo de retorno da API do CrowdTangle\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"status\": 200,\n",
    "    \"result\": {\n",
    "        \"posts\": [\n",
    "            {\n",
    "                \"platformId\": \"47657117525_10154014482272526\",\n",
    "                \"platform\": \"Facebook\",\n",
    "                \"date\": \"2016-02-12 23:38:14\",\n",
    "                \"updated\": \"2020-08-23 05:48:22\",\n",
    "                \"type\": \"live_video_complete\",\n",
    "                \"message\": \"Draymond at Foot Locker for #NBAAllStarTO with a special shoutout to #DubNation.\",\n",
    "                \"expandedLinks\": [\n",
    "                    {\n",
    "                        \"original\": \"https://www.facebook.com/warriors/videos/10154014482272526/\",\n",
    "                        \"expanded\": \"https://www.facebook.com/warriors/videos/10154014482272526/\"\n",
    "                    }\n",
    "                ],\n",
    "                \"link\": \"https://www.facebook.com/warriors/videos/10154014482272526/\",\n",
    "                \"postUrl\": \"https://www.facebook.com/warriors/posts/10154014482272526\",\n",
    "                \"subscriberCount\": 6041837,\n",
    "                \"score\": 4.750579867017164,\n",
    "                \"media\": [\n",
    "                    {\n",
    "                        \"type\": \"video\",\n",
    "                        \"url\": \"https://video-sea1-1.xx.fbcdn.net/v/t42.1790-29/12718926_1213464465334694_1083747983_n.mp4?_nc_cat=109&_nc_sid=985c63&efg=eyJybHIiOjQ0MiwicmxhIjoxNDIwLCJ2ZW5jb2RlX3RhZyI6InYyXzQwMF9jcmZfMjdfbWFpbl8zLjBfc2QifQ%3D%3D&_nc_ohc=e7Ygz2qv-24AX-wSWX2&rl=442&vabr=246&_nc_ht=video-sea1-1.xx&oh=889e0d776d92a84bb57099cad3d28d55&oe=5F43C879\",\n",
    "                        \"height\": 0,\n",
    "                        \"width\": 0\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"photo\",\n",
    "                        \"url\": \"https://scontent-sea1-1.xx.fbcdn.net/v/t15.5256-10/12526285_831341603658336_1493677499_n.jpg?_nc_cat=101&_nc_sid=1055be&_nc_ohc=DH0vfblGwtIAX_x8SBs&_nc_ht=scontent-sea1-1.xx&oh=b09d6378fa261fd45345e79c50c254cb&oe=5F696BE1\",\n",
    "                        \"height\": 400,\n",
    "                        \"width\": 400,\n",
    "                        \"full\": \"https://scontent-sea1-1.xx.fbcdn.net/v/t15.5256-10/12526285_831341603658336_1493677499_n.jpg?_nc_cat=101&_nc_sid=1055be&_nc_ohc=DH0vfblGwtIAX_x8SBs&_nc_ht=scontent-sea1-1.xx&oh=b09d6378fa261fd45345e79c50c254cb&oe=5F696BE1\"\n",
    "                    }\n",
    "                ],\n",
    "                \"statistics\": {\n",
    "                    \"actual\": {\n",
    "                        \"likeCount\": 24235,\n",
    "                        \"shareCount\": 753,\n",
    "                        \"commentCount\": 5675,\n",
    "                        \"loveCount\": 33,\n",
    "                        \"wowCount\": 18,\n",
    "                        \"hahaCount\": 3,\n",
    "                        \"sadCount\": 0,\n",
    "                        \"angryCount\": 5,\n",
    "                        \"thankfulCount\": 0,\n",
    "                        \"careCount\": 0\n",
    "                    },\n",
    "                    \"expected\": {\n",
    "                        \"likeCount\": 3927,\n",
    "                        \"shareCount\": 279,\n",
    "                        \"commentCount\": 1041,\n",
    "                        \"loveCount\": 1046,\n",
    "                        \"wowCount\": 94,\n",
    "                        \"hahaCount\": 45,\n",
    "                        \"sadCount\": 14,\n",
    "                        \"angryCount\": 19,\n",
    "                        \"thankfulCount\": 0,\n",
    "                        \"careCount\": 2\n",
    "                    }\n",
    "                },\n",
    "                \"account\": {\n",
    "                    \"id\": 19889,\n",
    "                    \"name\": \"Golden State Warriors\",\n",
    "                    \"handle\": \"warriors\",\n",
    "                    \"profileImage\": \"https://scontent-sea1-1.xx.fbcdn.net/v/t1.0-1/p200x200/74788912_10158146665972526_3545220405897723904_n.jpg?_nc_cat=1&ccb=2&_nc_sid=dbb9e7&_nc_ohc=9snUpG_pdlQAX90IhWM&_nc_ht=scontent-sea1-1.xx&tp=6&oh=f8a3d3b62b507966ecc68de3b557fe84&oe=5FBF1185\",\n",
    "                    \"subscriberCount\": 11580228,\n",
    "                    \"url\": \"https://www.facebook.com/47657117525\",\n",
    "                    \"platform\": \"Facebook\",\n",
    "                    \"platformId\": \"47657117525\",\n",
    "                    \"accountType\": \"facebook_page\",\n",
    "                    \"pageAdminTopCountry\": \"US\",\n",
    "                    \"verified\": true\n",
    "                },\n",
    "                \"videoLengthMS\": 307968,\n",
    "                \"liveVideoStatus\": \"completed\",\n",
    "                \"Id\": \"19889|10154014482272526\",\n",
    "                \"legacyid\": 1686762829\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Limitações e desafios\n",
    "\n",
    "* dados limitados a contas famosas\n",
    "    * contas menos famosas são subrepresentadas\n",
    "* não é possível saber quem reagiu ou comentou em posts\n",
    "* ferramenta muito nova / pouco explorada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coletando Posts no CrowdTangle\n",
    "\n",
    "* Utilizaremos a API do CrowdTangle para extrair posts do Facebook -- [documentação](https://github.com/CrowdTangle/API/wiki)\n",
    "* O primeiro passo é criar uma conta no CrowdTangle, depois criar um dashboard e obter o token da API para acessar os dados do dashboard\n",
    "* Para coletar posts via API, é necessário criar pelo menos uma lista em seu dashboard recém criado\n",
    "* Em nosso caso, criaremos uma lista para monitorar posts de páginas de mídias de notícias, incluindo CNN, NYT, BBC, NBC, NPR, Reuters, etc. \n",
    "* [Esse video explica como usar a interface do CrowdTangle para criar listas](https://vimeo.com/588999918). \n",
    "* [Esse video explica como acessar os dados via API](https://vimeo.com/453763307) explicando como executar todos os procedimentos acima\n",
    "\n",
    "> Observação: não é possível criar uma lista via API, somente pela interface do dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Credenciais da API do CrowdTangle\n",
    "\n",
    "print(\"Informe seu 'API_TOKEN'\")\n",
    "CROWDTANGLE_API_TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui coletamos os top 100 posts em cada mês, iniciando em start_date e terminando em end_date\n",
    "df_facebook_posts = DataExtraction().facebook(\n",
    "    CROWDTANGLE_API_TOKEN, \n",
    "    search_term='covid-19',\n",
    "    start_date = '2020-04-01',\n",
    "    end_date = '2021-04-01'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Amostra de posts do Facebook\n",
    "df_facebook_posts.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>3. Pré-processamento</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tokenização é um método para..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APAGAR\n",
    "\n",
    "import json\n",
    "\n",
    "example_file = 'data/tweets.json'\n",
    "tweets = open(example_file).read()\n",
    "tweets = json.loads(tweets)\n",
    "\n",
    "dados = [d['text'] for d in tweets]\n",
    "import pandas as pd\n",
    "dados = pd.DataFrame(dados, columns=['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing import Preprocessing\n",
    "\n",
    "pipeline = Preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['texto normalizado'] = dados['texto'].apply(pipeline.normalizacao)\n",
    "\n",
    "dados.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regex (Expressoes regulares)\n",
    "\n",
    "As expressão regulares são..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover_links = r'https?:\\/\\/.*[\\r\\n]*'\n",
    "aplicar_regex = lambda x: pipeline.limpeza_regex(x, remover_links, valor='LINK')\n",
    "dados['texto limpo'] = dados['texto normalizado'].apply(aplicar_regex)\n",
    "\n",
    "remover_mentions = r'@([A-Za-z0-9_]+)'\n",
    "aplicar_regex = lambda x: pipeline.limpeza_regex(x, remover_mentions, valor='USERNAME')\n",
    "dados['texto limpo'] = dados['texto limpo'].apply(aplicar_regex)\n",
    "\n",
    "dados.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenização\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['tokens'] = dados['texto limpo'].apply(pipeline.tokenizacao)\n",
    "\n",
    "dados.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stemmização é um método para..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['stems'] = dados['tokens'].apply(pipeline.stemmizacao)\n",
    "\n",
    "dados.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['lemmas'] = dados['tokens'].apply(pipeline.lemmatizacao)\n",
    "\n",
    "dados.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outra Alternativa: Pipeline de NLP do Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo tudo de uma só vez com Spacy\n",
    "\n",
    "dados['tokens'], dados['pos tags'], dados['lemmas'] = zip(*dados['texto'].apply(pipeline.nlp_pipeline))\n",
    "\n",
    "dados.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de Representação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos Estatísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_stats = ModelosEstatisticos()\n",
    "modelos_stats.bow(dados['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_stats.tfidf(dados['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO: PCA/SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = WordEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.word2vec(dados['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.fasttext(dados['texto'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentence Embeddings\n",
    "\n",
    "1. <span style=\"color:red\">SkipThought</span>\n",
    "2. InferSent\n",
    "3. **Universal Sentence Encoder (USE)**\n",
    "4. **SentenceBERT (SBERT)**\n",
    "5. Language-Agnostic SEntence Representations (LASER)\n",
    "6. Multilingual Universal Sentence Encoder (mUSE)\n",
    "7. **Language-agnostic BERT Sentence Embedding (LaBSE)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    # Smartphones\n",
    "    \"I like my phone\",\n",
    "    \"My phone is not good.\",\n",
    "    \"Your cellphone looks great.\",\n",
    "\n",
    "    # Weather\n",
    "    \"Will it snow tomorrow?\",\n",
    "    \"Recently a lot of hurricanes have hit the US\",\n",
    "    \"Global warming is real\",\n",
    "\n",
    "    # Food and health\n",
    "    \"An apple a day, keeps the doctors away\",\n",
    "    \"Eating strawberries is healthy\",\n",
    "    \"Is paleo better than keto?\",\n",
    "\n",
    "    # Asking about age\n",
    "    \"How old are you?\",\n",
    "    \"what is your age?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## SkipThought\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## InferSent\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# InferSent\n",
    "# Na primeira execução, é feito o download de arquivos de modelos e embeddings\n",
    "# Certifique-se de ter pelo menos 9GB disponíveis em disco para isso.\n",
    "# Devido ao download, a primeira execução é lenta\n",
    "infersent_embeddings = SentenceEmbeddings().infersent(sentences)\n",
    "infersent_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## USE\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# USE\n",
    "# Na primeira execução, é feito o download de arquivos de modelos e embeddings\n",
    "# Certifique-se de ter pelo menos 1GB disponível em disco para isso.\n",
    "# Devido ao download, a primeira execução é lenta\n",
    "use_embeddings = SentenceEmbeddings().use(sentences)\n",
    "use_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SBERT\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SBERT\n",
    "\n",
    "- Utilizaremos o modelo **all-MiniLM-L6-v2**, que é 5x mais rápido que sua versão base (**all-mpnet-base-v2**) e significativamente menor (de 420MB para 80MB), mas ainda mantém um bom desempenho\n",
    "- O termo **all-** indica que o modelo foi treinado com todos os dados disponíveis (mais de 1 bilhão de pares de treinamento) e são projetados como modelos de propósito geral\n",
    "- Para mais detalhes, acesse a página do [SBERT](https://www.sbert.net/docs/pretrained_models.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# SBERT\n",
    "sbert_embeddings = SentenceEmbeddings().sbert(sentences)\n",
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## LASER\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# LASER\n",
    "# Antes de utilizar o LASER, você deve fazer o download do modelo.\n",
    "# Para isso, descomente a linha abaixo.\n",
    "#!python -m laserembeddings download-models \"data\"\n",
    "# Você pode informar o código de idioma (ISO 639-1), para cada sentença da lista.\n",
    "# Por padrão, consideramos que todas as sentenças estão escritas em inglês (\"en\").\n",
    "laser_embeddings = SentenceEmbeddings().laser(sentences)\n",
    "laser_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## mUSE\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# mUSE\n",
    "# Na primeira execução, é feito o download de arquivos de modelos e embeddings\n",
    "# Certifique-se de ter pelo menos 300MB disponível em disco para isso.\n",
    "# Devido ao download, a primeira execução é lenta\n",
    "muse_embeddings = SentenceEmbeddings().muse(sentences)\n",
    "muse_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LaBSE\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# LaBSE\n",
    "labse_embeddings = SentenceEmbeddings().labse(sentences)\n",
    "labse_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Similaridade entre sentenças\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Exemplo baseado em:\n",
    "# https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder\n",
    "\n",
    "def plot_similarity(labels, features, rotation):\n",
    "  corr = np.inner(features, features)\n",
    "  sns.set(font_scale=1.2)\n",
    "  g = sns.heatmap(\n",
    "      corr,\n",
    "      xticklabels=labels,\n",
    "      yticklabels=labels,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      cmap=\"YlOrRd\")\n",
    "  g.set_xticklabels(labels, rotation=rotation)\n",
    "  g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "\n",
    "sent_emb = SentenceEmbeddings().labse(sentences) #escolha o modelo de sentence embeddings de sua preferência\n",
    "plot_similarity(sentences, sent_emb, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelagem e Extração de Conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Agrupamento de Textos\n",
    "- k-means\n",
    "- Agrupamento Hierárquico\n",
    "- Detecção de Comunidades em Grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### k-means\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Agrupamento Hierárquico\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Detecção de Comunidades em Grafos\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modelagem de Tópicos\n",
    "\n",
    "* Objetivo: identificar estruturas semânticas em um corpus\n",
    "* Processo não supervisionado\n",
    "* A ordem das palavras não importa, portanto podem ser usadas representações como o Bag of Words (BoW) ou Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Exemplos em um corpus de notícias\n",
    "\n",
    "* delimitar diferentes eventos (e.g., confronto entre Rússia e Ucrânia, Copa do Mundo, etc.)\n",
    "* identificar grandes temas (e.g., economia, política, educação, etc.)\n",
    "* pautas de discussão (e.g., aborto, questões climáticas, combate ao crime, etc.)\n",
    "* !!! Ou todos os casos acima misturados -- o que é comum de acontecer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Funcionamento de um modelo de tópicos\n",
    "\n",
    "* cada documento pode ser representado por um histograma com a contagem de cada termo contido nele\n",
    "* a forma desse histograma é proveniente de uma distribuição entre $k$ tópicos \n",
    "* os $k$ tópicos são distribuídos entre os termos no vocabulário do corpus\n",
    "\n",
    "O objetivo da modelagem de tópicos, então, é aprender essas distribuições.\n",
    "\n",
    "<img src=\"figs/topic-model.png\" style=\"float: center; zoom:100%;\" />\n",
    "\n",
    "Fonte: https://pyro.ai/examples/prodlda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Técnicas para modelagem de tópicos\n",
    "\n",
    "* Latent Dirichlet Allocation (LDA)\n",
    "* Latent Semantic Analysis (LSA) ou LSI (redução dimencional)\n",
    "* Probabilistic Semantic Analysis (pLSA) (versão probabilística do LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Pré-processamento para modelagem de tópicos\n",
    "\n",
    "* tentar preservar palavras que podem ser representativas para o domínio\n",
    "* não é necessário preservar a sequência dos termos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Desafios\n",
    "\n",
    "Obs: os exemplos a seguir são de tópicos identificados em um corpus de páginas web sobre as Eleições de 2018 no Brasil e Eleições de 2019 no Canadá.\n",
    "\n",
    "* Muitas vezes os tópicos são difíceis de serem caracterizados, necessitando conhecimento específico de domínio\n",
    "    * e.g. \"battisti, pf, italiano, italia, grafico, recurso, utc, extradicao, moro, deus\"\n",
    "    * e.g. \"pipeline, climate, oil, energy, fossil_fuel, carbon, france, kinsella, people_party, industry\"\n",
    "* As top N palavras de um tópico nem sempre delimitam claramente o assunto\n",
    "    * e.g. \"ex_presidente, ciro_gomes, ciro, artista, cunha, universidade, dilma, eduardo, classificar, reeleicao\"\n",
    "* O valor $k$ é escolhido manualmente\n",
    "    * mesmo usando métricas como score de coerência e distribuição dos tópicos ao longo do corpus, ainda é necessário o julgamento humano da adequabilidade do valor $k$\n",
    "* Tópico evoluem ao longo do tempo (para isso existem modelos temporais de tópicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Exemplo prático\n",
    "\n",
    "Ao final deste notebook, colocamos um exemplo prático usando o LDA em um dataset de notícias sobre as eleições canadenses de 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compreensão Semântica e Emocional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Detecção de Intenção\n",
    "\n",
    "<img src=\"figs/ir-example.png\" style=\"float: center; zoom:100%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Detecção de intenção\n",
    "- Uma intenção fornece uma interpretação geral do significado de uma expressão\n",
    "- Normalmente, é uma tarefa abstraída em um processo de classificação\n",
    "- Para isso, o primeiro passo é a obtenção de um conjunto de expressões rotuladas (*corpus*) para treinamento do modelo de classificação\n",
    "- Como veremos a seguir, existem muitos *corpus* disponíveis publicamente para essa tarefa.\n",
    "- Mas, caso deseje preparar o seu próprio *corpus* com dados de mídias sociais, você pode utilizar a modelagem de tópicos para determinar quais assuntos estão presentes no *corpus* e realizar a separação dos dados e, então, revisar e rotular manualmente cada um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Corpus\n",
    "- Iremos considerar o conjunto de dados disponível em [Wang, Jinpeng, et al.]<sup>[1](#footnoteIntentCorpus)</sup>\n",
    "- Categorias de intenção nos *tweets*: **Food & Drink, Travel, Career & Education, Goods & Services, Event & Activities, Trifle, Non-intent**\n",
    "- Veja na Tabela a seguir mais detalhes sobre os dados:\n",
    "\n",
    "<center> Tabela: Intenções e exemplos do conjunto de dados [Wang, Jinpeng, et al.]<sup>1</sup> </center>\n",
    "\n",
    "| Categoria | # (%) | Exemplo |\n",
    "| --- | --- | --- |\n",
    "| Food & Drink | 245 (11,5%) | hungry...i need a salad......four more days to the BEYONCE CONCERT... |\n",
    "| Travel | 187 (8,78%) | I need a vacation really bad. I need a trip to Disneyland! |\n",
    "| Career & Education | 159 (7,46%) | this makes me want to be a lawyer RT @someuser new favorite line from an ... |\n",
    "| Goods & Services | 251 (11,78%) | mhmmm, i wannna a new phoneeee. ... i have to go to the hospital. ... |\n",
    "| Event & Activities | 312 (15.07%) | on my way to go swimming with the twoon @someuser; i love her so muchhhhh! |\n",
    "| Trifle | 436 (20,47%) | I'm so happy that I get to take a shower with myself. :D |\n",
    "| Non-intent | 531 (24,92%) | So sad that Ronaldo will be leaving these shores...http://URL |\n",
    "\n",
    "\n",
    "<a name=\"footnoteIntentCorpus\">1</a>: Wang, Jinpeng, et al. \"Mining user intents in twitter: A semi-supervised approach to inferring intent categories for tweets.\" Twenty-Ninth AAAI Conference on Artificial Intelligence. 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modelo de Classificação de Intenções\n",
    "<br>\n",
    "\n",
    "<center>Redes Neurais Recorrentes (RNN) X Sentence Embeddings (imagem de [Feng et al. 2020])</center>\n",
    "\n",
    "<img src=\"figs/bilstm-ir.png\" style=\"float: left; zoom:60%;\" />\n",
    "<img src=\"figs/labse.png\" style=\"float: right; zoom:60%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#temporario\n",
    "intents = [\n",
    "    \"Smartphones\",\n",
    "    \"Smartphones\",\n",
    "    \"Smartphones\",\n",
    "\n",
    "    \"Weather\",\n",
    "    \"Weather\",\n",
    "    \"Weather\",\n",
    "\n",
    "    \n",
    "    \"Food and health\",\n",
    "    \"Food and health\",\n",
    "    \"Food and health\",\n",
    "    \n",
    "    \"Asking about age\",\n",
    "    \"Asking about age\"\n",
    "]\n",
    "\n",
    "intent_labse_model, X_test_labse, y_test_labse, classes = SemanticComprehension().training_intents(\"labse\", sentences, intents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs = 20\n",
    "# Batch size = 32\n",
    "# Hidden layers = 300\n",
    "# Max sequence length = 280 --> tweet size\n",
    "intent_bilstm_model, X_test_rnn, y_test_rnn, classes = SemanticComprehension().training_intents(\"bilstm\", sentences, intents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaBSE's performance\n",
    "y_hat = intent_labse_model.predict(X_test_labse)\n",
    "SemanticComprehension().plot_confusion_matrix(y_test_labse, y_hat, classes, \"figs/ir-labse-cm.png\")\n",
    "\n",
    "# RNN's performance\n",
    "y_hat = intent_bilstm_model.predict(X_test_rnn)        \n",
    "SemanticComprehension().plot_confusion_matrix(np.argmax(y_test_rnn,axis=1), np.argmax(y_hat, axis=1), classes, \"figs/ir-rnn-cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix de Confusão\n",
    "<br>\n",
    "\n",
    "<center>Redes Neurais Recorrentes (RNN) X Sentence Embeddings</center>\n",
    "\n",
    "<img src=\"figs/ir-rnn-cm.png\" style=\"float: left; zoom:22%;\" />\n",
    "<img src=\"figs/ir-labse-cm.png\" style=\"float: right; zoom:22%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Predição de intents para os tweets coletados\n",
    "intents = CompreensaoSemantica().predicao_intencoes(intent_labse_model, sentences) ## configurado apenas para o modelo LaBSE\n",
    "intents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reconhecimento de Entidades Nomeadas\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Corpus\n",
    "- Iremos considerar o conjunto de dados disponível em  https://www.kaggle.com/code/amoghjrules/twitter-entity-recognition-using-bilstms\n",
    "- abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "entities = []\n",
    "for sentence in tqdm(sentences):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(sentence)\n",
    "    entity = {}\n",
    "    for i, ent in enumerate(doc.ents):\n",
    "        entity[i] = {\n",
    "                        \"value\":ent.text,\n",
    "                        \"entity\":ent.label_,\n",
    "                        \"start\":ent.start_char,\n",
    "                        \"end\":ent.end_char\n",
    "                    }\n",
    "    entities.append(entity)\n",
    "\n",
    "print(entities[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Análise de Sentimentos (AS)\n",
    "\n",
    "* Também conhecida como **Mineração de Opiniões**\n",
    "* AS é o \"estudo computacional das opiniões, atitudes e emoções de pessoas em relação a uma entidade\" [Medhat et al. 2014]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tarefas de AS\n",
    "\n",
    "* **Detecção de sentimento**\n",
    "    - e.g. positivo, negativo ou neutro\n",
    "* **Identificação de emoções**\n",
    "    - e.g. sentimentos como raiva, antecipação, nojo, medo, alegria, tristeza, surpresa, confiança, etc. \n",
    "* **Detecção de toxicidade** \n",
    "    - e.g. categorias como insulto, profanidade, conteúdo sexualmente explícito, etc. [Jigsaw 2022]\n",
    "* **Análise multilíngue de sentimentos**\n",
    "* **Detecção de sarcasmo**\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exemplos de aplicações de AS\n",
    "\n",
    "* Identificação de comentários agressivos em notícias [Jigsaw 2022]\n",
    "* Extração da opinião pública sobre um candidato ou partido político [Pang et al. 2008]\n",
    "* Priorização de respostas a avaliações negativas de produtos [Bougie et al. 2003] \n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Vantages da AS\n",
    "\n",
    "* Permite análises em larga escala\n",
    "* Reduz a subjetividade provocada por avaliadores humanos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Níveis da AS\n",
    "\n",
    "1. **Nível de documento** - premissa: documento expressa opinião sobre apenas uma entidade; \n",
    "2. **Nível de frase** - premissa: frase expressa opinião sobre apenas uma entidade;  \n",
    "3. **Nível de aspecto** - múltiplas opiniões sobre múltiplos aspectos (ou alvos)\n",
    "    - e.g. “A <span style=\"color:#f00\">qualidade de voz</span> deste telefone <span style=\"color:#f00\">não é boa</span>, mas a <span style=\"color:#00f\">vida útil da bateria</span> é <span style=\"color:#00f\">longa</span>”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Abordagens para criação de modelos de AS\n",
    "\n",
    "1. **Usando Léxicos** \n",
    "    * <span style=\"color: #088B00\">VANTAGEM</span>: independência de domínio\n",
    "    * <span style=\"color: #f00\">DESVANTAGEM</span>: menor precisão e baixa escalabilidade\n",
    "2. **Aprendizado de máquina (ML)**\n",
    "    * <span style=\"color: #088B00\">VANTAGEM</span>: maior precisão\n",
    "    * <span style=\"color: #f00\">DESVANTAGEM</span>: maior dependência de domínio\n",
    "3. **Híbrido (léxico + ML)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### A seguir iremos apresentar\n",
    "\n",
    "* EmoLex\n",
    "* LIWC\n",
    "* Perspective API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Frases que vamos usar como exemplo para os modelos de AS\n",
    "\n",
    "emotional_sentences = [\n",
    "\n",
    "    # exemplo de frase positiva\n",
    "    \"How good it is to live in Curitiba!\",\n",
    "\n",
    "    # exemplo de frase neutra\n",
    "    \"This car is grey.\",\n",
    "\n",
    "    # exemplo de frase negativa\n",
    "    \"Shut up, you're an idiot!\",\n",
    "\n",
    "    # exemplo de frase negativa, mas com palavras que podem confundir o modelo de AS como \"friend\"\n",
    "    \"It must be so sad to have you as a friend\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### EmoLex\n",
    "\n",
    "* Criado em 2013, é um dos maiores léxicos disponíveis em língua Inglesa\n",
    "* Baseado em unigramas e bigramas dos léxicos\n",
    "    * General Inquirer Lexicon\n",
    "    * WordNet Affect Lexicon\n",
    "* Anotações feitas via crowdsourcing pelo Mechanical Turk\n",
    "* Associa palavras com as oito emoções da teoria de Plutchik [Plutchik 1980]\n",
    "    * raiva, medo, antecipação, confiança, surpresa, tristeza, alegria e desgosto\n",
    "* Também inclui as catergorias de sentimento negativo e positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de sentenças processadas com o Emolex (frequência de emoções nas sentenças)\n",
    "EmotionComprehension.emolex(emotional_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### LIWC\n",
    "\n",
    "* Ferramenta para identificar características linguísticas, psicológicas e sociais em textos [Pennebaker et al. 2001]\n",
    "* AS baseada em léxico (um dos maiores e mais completos na quantidade de termos e categorias cobertas)\n",
    "* Léxicos separados para línguas diferentes, sendo o inglês a língua padrão\n",
    "* Disponível apenas para Windows via interface gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Categorias de conteúdo disponíveis no LIWC\n",
    "\n",
    "* **emoções positivas** (e.g. amor, legal, doce, etc.)\n",
    "* **emoções negativas** (e.g. ferido, feio, desagradável, etc.)\n",
    "* **processos sociais** (e.g. filha, marido, vizinho, adulto, bebê, etc.)\n",
    "* **processos cognitivos** (e.g. pensar, conhecer, causa, etc.)\n",
    "* **processos perceptivos** (e.g. observar, escutar, sentir, etc.)\n",
    "* **processos biológicos** (e.g. comer, sangue, dor, etc.)\n",
    "* **relatividade** (e.g. chega, vai, embaixo, ontem, até, fim, etc.)\n",
    "* **preocupações sociais** (e.g. auditar, igreja, cozinhar, trabalhar, mestrado, etc.)\n",
    "* **consentimento** (e.g. concordar, ok, etc.)\n",
    "* **não-fluências e palavras de preenchimento** (e.g. hm, er, umm, certo, etc.)\n",
    "* entre outras [Tausczik and Pennebaker 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Categorias de função disponíveis no LIWC\n",
    "\n",
    "* **pronomes** \n",
    "* **preposições** \n",
    "* **artigos** \n",
    "* **conjunções** \n",
    "* **verbos auxiliares** \n",
    "* entre outras [Tausczik and Pennebaker 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Interface do LIWC\n",
    "\n",
    "<img src=\"figs/liwc.png\" style=\"float: center; zoom:100%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Exemplo de processamento com o LIWC\n",
    "\n",
    "Para executar o processamento das sentenças de exemplo, será necessário [adquirir uma licença](https://www.liwc.app/buy), instalar o LIWC em um computador com Windows e processar o arquivo .csv gerado na célula a seguir. \n",
    "\n",
    "Você também poderá usar a versão de [teste online](https://www.liwc.app/demo), inserindo manualmente cada uma das sentenças geradas no .csv a seguir (essa versão é limitada a algumas poucas categorias, mas estão disponíveis as categorias de \"Negative tone\" e \"Positive tone\", bastante úteis em tarefas de AS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cria um .csv com exemplos para ser processado pelo LIWC\n",
    "pd.DataFrame({'text': emotional_sentences}).to_csv('data/emotional_sentences_LIWC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# carrega o arquivo com exemplos processado pelo LIWC\n",
    "df_LIWC = pd.read_csv('emotional_sentences_LIWC.csv')\n",
    "\n",
    "# apresenta apenas algumas colunas mais interessantes para AS\n",
    "df_LIWC[['text', 'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Perspective API\n",
    "\n",
    "* Usado para identificação de toxicidade em comentários online\n",
    "* Modelo multilíngue\n",
    "* Disponibilizado gratuitamente por meio de uma iniciativa da Jigsaw, uma empresa da Google [Jigsaw 2022]\n",
    "* Acessado via API pública\n",
    "* Adotada pelos principais veículos jornalísticos internacionais para moderar comentários em seus portais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Desafios para identificar toxicidade em comentários\n",
    "\n",
    "* Geralmente são textos curtos - ex.: “sei… 😏”, “¬¬”, “no way!”\n",
    "* Uso de emojis ambíguos - ex.: 😏,🌚,😋 \n",
    "* Erros de ortografia propositais (ou não) - ex.: “çocorro”;\n",
    "* Gírias da internet - ex.: “vc”, “pq”, “lol”, “iti malia”\n",
    "* Sutilezas inerentes à língua ou localidade - ex.: “oxi”, “p**ra!”;\n",
    "* Especificidades de contexto - ex.: “ex-presidiário”, “bozo”;\n",
    "* Uso de figuras de linguagem - ex.: metáfora, ironia, etc.;\n",
    "* Susceptíveis a ataques adversários - ex.: “st.Up1d”\n",
    "* Podem ocorrer de forma esparsa no conjunto de dados;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Definição de comentário tóxico\n",
    "\n",
    "<center>\"Um comentário rude, desrespeitoso ou irracional que provavelmente fará você sair de uma discussão.\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Funcionamento do Perspective API\n",
    "\n",
    "* Atribui uma pontuação contínua entre 0 e 1 para diferentes categorias de toxicidade de acordo com o % no texto\n",
    "* Uma pontuação mais alta para uma determinada categoria (ou atributo), indica uma maior probabilidade de um leitor perceber que o comentário possui este atributo\n",
    "* e.g. “Você é um idiota” pode receber uma pontuação de $0.8$ para o atributo TOXICIDADE, indicando que 8 entre 10 pessoas perceberiam esse comentário como tóxico\n",
    "* Portanto um comentário com pontuação de TOXICIDADE de $0.9$ não necessariamente é mais tóxico  que uma com $0.7$\n",
    "\n",
    " [Jigsaw 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src=\"figs/perspective.png\" style=\"float: center; zoom:100%;\" />\n",
    "\n",
    "Fonte: https://perspectiveapi.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Atributos de produção (multilíngue)\n",
    "\n",
    "- **TOXICITY** - “Um comentário rude, desrespeitoso ou irracional que provavelmente fará com que as pessoas deixem uma discussão”; \n",
    "- **SEVERE_TOXICITY** - “Um comentário que é muito odioso, agressivo, desrespeitoso, ou muito provável de fazer um usuário sair de uma discussão, ou desistir de compartilhar sua perspectiva. Este atributo é muito menos sensível a formas mais leves de toxicidade, como comentários que incluem usos positivos de palavrões”; \n",
    "- **IDENTITY_ATTACK** - “Comentários negativos ou de ódio direcionados a alguém por causa de sua identidade”; \n",
    "- **INSULT** - “Comentário ofensivo, inflamatório ou negativo para uma pessoa ou grupo de pessoas”; \n",
    "- **PROFANITY** - “Xingamentos, palavrões ou outras linguagens obscenas, ou profanas”; \n",
    "- **THREAT** - “Descreve a intenção de infligir dor, lesão ou violência contra um indivíduo, ou grupo”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Acessando o Perspective API\n",
    "\n",
    "* Para executar os exemplos a seguir, você deverá solicitar acesso ao Perspective API no Google Cloud seguindo [esse passo a passo](https://developers.perspectiveapi.com/s/docs-get-started)\n",
    "* Obtenha a chave da API para usar nos próximos passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Credenciais do Perspective API\n",
    "\n",
    "print(\"Informe seu 'API KEY'\")\n",
    "PERSPECTIVE_API_KEY = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exemplo de sentenças processadas com o Perspective API\n",
    "EmotionComprehension.perspective(emotional_sentences, PERSPECTIVE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# <center>6. Aplicações</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 6.1 Polarização Política\n",
    "\n",
    "TODO: contextualizar a seção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Análise e pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Carregando os conjuntos de dados de notícias e retweets com links para as notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataframe_from_drive_csv(url):\n",
    "    path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "# news dataset\n",
    "url = 'https://drive.google.com/file/d/1AQjdqe9QRFK7ydNteZPM_IJk1eH-H3n_/view?usp=share_link'\n",
    "df_news = load_dataframe_from_drive_csv(url)\n",
    "\n",
    "# retweeted links dataset\n",
    "url = 'https://drive.google.com/file/d/1Nn0I_tZnBWgUTNDeeE4bGzVTBhrTOJo1/view?usp=share_link'\n",
    "df_retweeted_urls = load_dataframe_from_drive_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Quantidade de notícias no conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Exemplos de dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "df_news[['retweets_count', 'title', 'description', 'article']].sort_values('retweets_count', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Remoção de notícias duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news = df_news.drop_duplicates(subset=['title', 'url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Combinação do título + descrição + corpo do artigo em uma única string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['text'] = df_news['title'].astype(str) + ' ' + df_news['description'].astype(str) + ' ' + df_news['article'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Estatísticas sobre o tamanho dos textos\n",
    "\n",
    "* Textos longos (> 4500 caracteres em média)\n",
    "* O menor texto tem 310 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['text_length'] = df_news['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['text_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Exemplos de notícias\n",
    "\n",
    "* Escrita formal\n",
    "* Sem erros de ortografia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for content in df_news.sample(3)['text'].to_list():\n",
    "    print(content[:500], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Pré-processamento dos textos\n",
    "\n",
    "* Remoção de \n",
    "    * links \n",
    "    * caracteres isolados \n",
    "    * stop-words\n",
    "* Lematização usando Spacy\n",
    "* Transoformação em lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import re\n",
    "\n",
    "# Instalação das dependências em inglês para a biblioteca Spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Stopwords em inglês contidas na biblioteca Spacy\n",
    "stop_words = list(spacy_nlp.Defaults.stop_words)\n",
    "\n",
    "# Stopwords em inglês contidas na biblioteca do NLTK\n",
    "stop_words += nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Algumas outras palavras para serem removidas além das stop-words\n",
    "stop_words += [\n",
    "    '-pron-', 'video', 'try', 'refresh', 'continue', 'article', 'load', 'browser', 'say', 'will', \n",
    "    'would', 'content', 'news', 'sign', 'register', 'home', 'page', 'advertisement'\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "    # Remoção de links \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Transforma o texto em um documento Spacy\n",
    "    spacy_doc = spacy_nlp(text)\n",
    "\n",
    "    # Usa o Spacy para lematizar o texto e remover stop words\n",
    "    tokens = [token.lemma_.lower() for token in spacy_doc if token.lemma_.lower() not in stop_words]\n",
    "\n",
    "    # Remove caracteres isolados\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['text'] = df_news['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Exemplos de notícias pré-processadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['text'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Frequência de termos mais representativos após o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seta os padrões default para o matplot\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "def get_all_terms(corpus):\n",
    "    terms = []\n",
    "    for text in corpus:\n",
    "        terms = terms + text\n",
    "    return terms\n",
    "\n",
    "\n",
    "def term_frequency(corpus, num_plot=50, num_show=1000):\n",
    "    plt.figure(figsize=(15, 5)) \n",
    "\n",
    "    terms = get_all_terms(corpus)\n",
    "    fdist = nltk.FreqDist(terms)\n",
    "\n",
    "    if num_plot > 0:\n",
    "        fdist.plot(num_plot)\n",
    "\n",
    "    # return a dataframe with terms and frequencies\n",
    "    data = [[term, frequency] for term, frequency in fdist.most_common(num_show)]\n",
    "    return pd.DataFrame(data, columns=['TERM', 'FREQUENCY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_terms = term_frequency(df_news['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Geração de bi e trigramas\n",
    "\n",
    "Usando o Gemsim para formar bi e trigramas caso os termos coocorram pelo menos 10 vezes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "\n",
    "def make_trigrams(corpus, min_count=5, threshold=10):\n",
    "\n",
    "    # Criar os modelos de bi e trigramas\n",
    "\n",
    "    # Obs.: quanto maior o threshold, menos N-gramas são formados\n",
    "    bigram = Phrases(corpus, min_count=min_count, threshold=threshold)\n",
    "    bigram_model = Phraser(bigram)\n",
    "\n",
    "    trigram = Phrases(bigram[corpus], min_count=min_count, threshold=threshold)\n",
    "    trigram_model = Phraser(trigram)\n",
    "\n",
    "    return [trigram_model[bigram_model[text]] for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['text'] = make_trigrams(df_news['text'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Exemplos de notícias com bi e trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Termos mais representativos após a identificação de bi e trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_terms = term_frequency(df_news['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Remoção de termos sem valor para o domínio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for term in df_terms['TERM'].to_list():\n",
    "    if len(term) > 15:\n",
    "        print(\"'\" + term + \"',\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### A partir da lista acima, são selecionados manualmente quais termos devem ser removidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unuseful_terms = [\n",
    "    'apologize_fail_tap_team',\n",
    "    'postmedia_network',\n",
    "    'network_latest_national_stories',\n",
    "    'soon_inbox_encounter_issue',\n",
    "    'click_unsubscribe_link_email',\n",
    "    'inc._365_bloor_street',\n",
    "    'ontario_m4w_3l4_416',\n",
    "    'thank_welcome_email_way',\n",
    "    'check_junk_folder_issue',\n",
    "    'story_midday_sun_newsroom',\n",
    "    'inbox_noon_late_headline',\n",
    "    'story_opinion_photo_toronto',\n",
    "    'sun_email_address_error',\n",
    "    'provide_valid_email_address',\n",
    "    'click_button_consent_receive',\n",
    "    'newsletter_postmedia_network_inc.',\n",
    "    'unsubscribe_time',\n",
    "    'original_archive'\n",
    "]\n",
    "\n",
    "def remove_unuseful_terms(text):\n",
    "    return [token for token in text if token.lower() not in unuseful_terms]\n",
    "\n",
    "df_news['text'] = df_news['text'].apply(remove_unuseful_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Identificação de tópicos com LDA\n",
    "\n",
    "Referência: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Criação do dicionário e corpus para o LDA usando o modelo BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Cria o dicionário a partir do corpus\n",
    "gs_dictionary = Dictionary(df_news['text'])\n",
    "\n",
    "# Remove os tokens muito raros (menos frequentes que `no_below`) ou muito comuns (mais frequentes que `no_above`%)\n",
    "gs_dictionary.filter_extremes(no_below=3, no_above=.20)\n",
    "\n",
    "# Cria o corpus usando o modelo de Bag of Words\n",
    "gs_corpus = [gs_dictionary.doc2bow(text) for text in df_news['text'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Dictionary size:', len(gs_dictionary), ', corpus size:', len(gs_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Treinamento de modelos LDA \n",
    "\n",
    "* Para treinar os modelos LDA usamos diferentes valores para $k$ \n",
    "* Nesse tutorial, escolhemos $k=10$ até $k=30$, uma vez que temos aprox. 500 documentos no corpus\n",
    "* Para cada modelo geramos o score de coerência e perplexidade, que são analisados a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "\n",
    "def compute_lda_performance(dictionary, corpus, texts, start=1, limit=50, step=1):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    perplexity_values : Perplexity values corresponding to the LDA model with respective number of topics\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    num_topics_values = []\n",
    "    perplexity_values = []\n",
    "    coherence_values = []\n",
    "    for num_topics in range(start, limit+step, step):\n",
    "        num_topics_values.append(num_topics)\n",
    "\n",
    "        model = LdaMulticore(corpus=corpus, num_topics=num_topics, iterations=1000, id2word=dictionary, passes=10, random_state=100) \n",
    "\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence = coherencemodel.get_coherence()\n",
    "        coherence_values.append(coherence)\n",
    "\n",
    "        perplexity = model.log_perplexity(corpus)\n",
    "        perplexity_values.append(perplexity)\n",
    "\n",
    "        print('Topics:', num_topics, '\\tPerplexity:', round(perplexity, 5), '\\tCoherence:', round(coherence, 5))\n",
    "\n",
    "    df_results = pd.DataFrame({'topics': num_topics_values, 'perplexity': perplexity_values, 'coherence': coherence_values})\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lda_models = compute_lda_performance(dictionary=gs_dictionary, corpus=gs_corpus, texts=df_news['text'], start=10, limit=30, step=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Análise do score de coerência\n",
    "\n",
    "* Indica o quão \"interpretável\" são os tópicos para humanos\n",
    "* Indica o quanto as palavras mais representativas de cada tópico são similares entre si\n",
    "* Diferentes medidas de similaridade podem ser usadas, a padrão é o score c_v, que usa similaridade do cosseno\n",
    "* Heurística: quanto maior o score de coerência, melhor (mas nem sempre)\n",
    "    * Usar método do \"cotovelo\"\n",
    "    * Analisar o gráfico de tópicos (a seguir)\n",
    "    * Usar bom senso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scores de coerência de acordo com o número de tópicos\n",
    "ax = df_lda_models.plot.line(x='topics', y='coherence')\n",
    "ax.set_xlabel(\"Num Topics\")\n",
    "ax.set_ylabel(\"Coherence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Top 5 modelos\n",
    "df_lda_models.sort_values('coherence', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Identifica o melhor número de tópicos de acordo com o score de coerência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_num_topics = df_lda_models.sort_values('coherence', ascending=False)['topics'].tolist()[0]\n",
    "\n",
    "best_num_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Treinamento do modelo com o melhor número de tópicos \n",
    "\n",
    "Aqui repetimos o treinamento do modelo com o melhor número de tópicos usando uma quantidade maior de iterações e passes no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=gs_corpus, num_topics=best_num_topics, \n",
    "                   iterations=10000, id2word=gs_dictionary, passes=100, \n",
    "                   random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Coerência e perplexidade do modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity (lower is better)\n",
    "print('\\nPerplexity: ', lda.log_perplexity(gs_corpus)) \n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=df_news['text'], \n",
    "                                     dictionary=gs_dictionary, coherence='c_v')\n",
    "print('\\nCoherence Score: ', coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Palavras mais representativas de cada tópico\n",
    "\n",
    "Alguns exemplos de tópicos:\n",
    "\n",
    "* **IMPOSTO DE CARBONO:** carbon_tax, emission, climate_change, tax, cbc, economy, cent, target, cost, program \n",
    "* **ABORTO:** abortion, debate, harper, comment, conservative_party, sex_marriage, law, view, conservative_leader, montreal \n",
    "* **PESQUISA ELEITORAL:** poll, mr._scheer, cent, mr._trudeau, survey, research, 30, age, positive, centre \n",
    "* **CORTE ORÇAMENTÁRIO:** billion, cut, platform, million, city, toronto, tax, bernier, budget, spending \n",
    "* **CASO DE RACISMO:** blackface, racist, apologize, black, apology, rcmp, woman, racism, global, makeup \n",
    "* **PETRÓLEO:** pipeline, oil, climate_change, climate, company, energy, encana, coal, spend, money \n",
    "* **IMIGRAÇÃO:** insurance, claim, refugee, comment, act, facebook, immigrant, immigration, insurance_broker, anti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, topic in enumerate(lda.top_topics(topn=5, texts=df_news['text'])):\n",
    "    terms = topic[0]\n",
    "    print('Topic', i, ', '.join([term[1] for term in terms]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Visualização dos tópicos\n",
    "\n",
    "* Cada bolha representa um tópico. Quanto maior a bolha, mais prevalente é esse tópico.\n",
    "* Um bom modelo de tópico terá bolhas grandes e não sobrepostas espalhadas por todo o gráfico.\n",
    "* Um modelo com muitos tópicos normalmente terá muitas sobreposições, bolhas de tamanho pequeno agrupadas em uma região do gráfico.\n",
    "\n",
    "Fonte: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "def show_lda_vis(lda, gs_corpus, gs_dictionary):\n",
    "    # Workaround para evitar que o pyLDAvis esconda os botões do Jupyterlab\n",
    "    from IPython.display import HTML\n",
    "    css_str = '<style> \\\n",
    "    .jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    "    .bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    "    .jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "    text.terms { fill: #616161;} \\\n",
    "    </style>'\n",
    "    display(HTML(css_str))\n",
    "\n",
    "    # feed the LDA model into the pyLDAvis instance\n",
    "    warnings.filterwarnings('ignore')\n",
    "    return gensimvis.prepare(lda, gs_corpus, gs_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_lda_vis(lda, gs_corpus, gs_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Salva os 3 tópicos mais representativos de cada notícia no dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_2_words = {}\n",
    "for topic in lda.show_topics(num_topics=100, num_words=10, formatted=False):\n",
    "    topic_id = topic[0]\n",
    "    topic_tokens = ', '.join([token[0] for token in topic[1]])\n",
    "    topic_2_words[topic_id] = topic_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_topics_1 = []\n",
    "doc_topics_1_words = []\n",
    "doc_topics_1_percentages = []\n",
    "\n",
    "doc_topics_2 = []\n",
    "doc_topics_2_words = []\n",
    "doc_topics_2_percentages = []\n",
    "\n",
    "doc_topics_3 = []\n",
    "doc_topics_3_words = []\n",
    "doc_topics_3_percentages = []\n",
    "\n",
    "for i, doc in enumerate(df_news['text'].to_list()):\n",
    "    doc_bow = gs_dictionary.doc2bow(doc)\n",
    "    \n",
    "    # get document topics (each row contains a tuple with topic id and topic probability)\n",
    "    doc_topics = lda.get_document_topics(doc_bow)\n",
    "    \n",
    "    # sort topics by probability\n",
    "    doc_topics.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    # get them main topic and top 3 topics\n",
    "    topics = doc_topics[:3]\n",
    "    \n",
    "    if len(topics) > 0:\n",
    "        doc_topics_1_percentages.append(topics[0][1])\n",
    "        topic_id = topics[0][0]\n",
    "        doc_topics_1.append(topic_id)\n",
    "        doc_topics_1_words.append(topic_2_words[topic_id])\n",
    "    else:\n",
    "        doc_topics_1.append(None)\n",
    "        doc_topics_1_percentages.append(None)\n",
    "        doc_topics_1_words.append(None)\n",
    "        \n",
    "        \n",
    "    if len(topics) > 1:\n",
    "        doc_topics_2_percentages.append(topics[1][1])\n",
    "        topic_id = topics[1][0]\n",
    "        doc_topics_2.append(topic_id)\n",
    "        doc_topics_2_words.append(topic_2_words[topic_id])\n",
    "    else:\n",
    "        doc_topics_2.append(None)\n",
    "        doc_topics_2_percentages.append(None)\n",
    "        doc_topics_2_words.append(None)\n",
    "        \n",
    "        \n",
    "    if len(topics) > 2:\n",
    "        doc_topics_3_percentages.append(topics[2][1])\n",
    "        topic_id = topics[2][0]\n",
    "        doc_topics_3.append(topic_id)\n",
    "        doc_topics_3_words.append(topic_2_words[topic_id])\n",
    "    else:\n",
    "        doc_topics_3.append(None)\n",
    "        doc_topics_3_percentages.append(None)\n",
    "        doc_topics_3_words.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news['topic'] = pd.Series(doc_topics_1)\n",
    "df_news['topic_words'] = pd.Series(doc_topics_1_words)\n",
    "df_news['topic_percentage'] = pd.Series(doc_topics_1_percentages)\n",
    "\n",
    "df_news['topic_1'] = pd.Series(doc_topics_1)\n",
    "df_news['topic_1_words'] = pd.Series(doc_topics_1_words)\n",
    "df_news['topic_1_percentage'] = pd.Series(doc_topics_1_percentages)\n",
    "\n",
    "df_news['topic_2'] = pd.Series(doc_topics_2)\n",
    "df_news['topic_2_words'] = pd.Series(doc_topics_2_words)\n",
    "df_news['topic_2_percentage'] = pd.Series(doc_topics_2_percentages)\n",
    "\n",
    "df_news['topic_3'] = pd.Series(doc_topics_3)\n",
    "df_news['topic_3_words'] = pd.Series(doc_topics_3_words)\n",
    "df_news['topic_3_percentage'] = pd.Series(doc_topics_3_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Distribuição dos tópicos mais representativos em cada notícia\n",
    "\n",
    "* O tópico mais representativo (em azul) tem alta dominância para a maioria das notícias\n",
    "* O segundo e terceiro tópicos mais representativos, em laranja e verde, tem uma representatividade baixa na maioria das notícias em comparação com o azul. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax1 = pd.Series(doc_topics_1_percentages).plot.hist(bins=25)\n",
    "ax2 = pd.Series(doc_topics_2_percentages).plot.hist(bins=25)\n",
    "ax3 = pd.Series(doc_topics_3_percentages).plot.hist(bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Distribuição dos tópicos mais dominantes entre as notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_news.groupby('topic_1').agg({\n",
    "    'article': 'count'\n",
    "}).reset_index().rename(columns={\n",
    "    'topic_1': 'dominant topic id',\n",
    "    'article': 'number of news',\n",
    "}).sort_values('number of news', ascending=False)\n",
    "\n",
    "df['dominant topic id'] = df['dominant topic id'].astype('int')\n",
    "\n",
    "ax = df.plot.bar(x='dominant topic id', y='number of news', figsize=(15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['number of news'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "#### Exemplos de manchetes em 5 tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    print('\\nTopic', i)\n",
    "    print(df_news[df_news['topic'] == i]['title'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topic_1(url):\n",
    "    df = df_news[df_news['url'] == url]\n",
    "    return df.iloc[0]['topic'] if df.shape[0] == 1 else None\n",
    "\n",
    "def get_topic_1_words(url):\n",
    "    df = df_news[df_news['url'] == url]\n",
    "    return df.iloc[0]['topic_words'] if df.shape[0] == 1 else None\n",
    "\n",
    "df_retweeted_urls['topic'] = df_retweeted_urls['retweeted_url'].apply(get_topic_1)\n",
    "df_retweeted_urls['topic_words'] = df_retweeted_urls['retweeted_url'].apply(get_topic_1_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Resultados\n",
    "\n",
    "Heatmap de tópicos vs retweets de usuários por faixa de polaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def relative_polarity_heatmap(df, column, oversample=True, title=None, x_label=None, y_label_left=None, y_label_right=None, \n",
    "                              cbar_label=None, top_n=20, vmax=1, numeric_index=False, only_dataframe=False):\n",
    "    \n",
    "    env_polarities = [value/10 for value in range(-10,11,1)]\n",
    "    \n",
    "    df_copy = df.copy()    \n",
    "    \n",
    "    \"\"\"\n",
    "    -------------------\n",
    "    RP(H) calculation\n",
    "    -------------------\n",
    "    \"\"\"\n",
    "\n",
    "    # generate a matrix with rows being 'column' parameter values and columns being polarities from -1 to +1\n",
    "    df = pd.crosstab(index=df[column], columns=df['user_P(H)_bin'], values=df[column], aggfunc='count')\n",
    "    df = df.fillna(0.0)\n",
    "    \n",
    "    # add faulting columns (for faulting polarities)\n",
    "    for polarity in env_polarities:\n",
    "        if not polarity in df.columns:\n",
    "            num_rows = df.shape[0]\n",
    "            df[polarity] = pd.Series([0.0] * num_rows)\n",
    "            \n",
    "    # reorder columns from -1.0 to +1.0\n",
    "    df = df[env_polarities]\n",
    "    \n",
    "    # scale by dividing the retweets count of each polarity for each domain by the max retweets count of each polarity from all domains\n",
    "    if oversample:\n",
    "        df_polarity_max_retweets = df.max(axis=0) # get polarity column max value\n",
    "        for polarity in env_polarities:\n",
    "            df[polarity] = df[polarity] / df_polarity_max_retweets[polarity]    \n",
    "    \n",
    "    # normalize values to 0-1 interval with min-max (by domain min-max from all polarities)\n",
    "    max_df = df.max(axis=1)\n",
    "    min_df = df.min(axis=1)\n",
    "    for polarity in env_polarities:\n",
    "        df[polarity] = (df[polarity] - min_df) / (max_df - min_df) \n",
    "       \n",
    "    # calculate polarity average without zeros and neutral users count\n",
    "    relative_polarities = []\n",
    "    for i, row in df.iterrows():\n",
    "        row_sum = 0\n",
    "        count = 0\n",
    "        for polarity in env_polarities:\n",
    "            if polarity != 0.0 and row[polarity] > 0.0: # only count cells with non zero value and remove the neutral polarity\n",
    "                row_sum += row[polarity] * polarity\n",
    "                count += row[polarity]\n",
    "        if count > 0:\n",
    "            relative_polarities.append(row_sum / count)\n",
    "        else:\n",
    "            relative_polarities.append(None)\n",
    "        \n",
    "    df['relative_polarity'] = relative_polarities\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    -------------------\n",
    "    Data preparation\n",
    "    -------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    # count occurrences of 'column' values\n",
    "    df_rphs = df_copy.groupby(column).agg(\n",
    "        retweets_count=pd.NamedAgg(column=column, aggfunc='count')\n",
    "    ).sort_values(by=column, ascending=False)\n",
    "    df_rphs[column] = df.sort_index(ascending=False).index\n",
    "    df_rphs['RP(H)'] = df.sort_index(ascending=False)['relative_polarity']\n",
    "    \n",
    "    \"\"\"\n",
    "    -------------------\n",
    "    Data visualization\n",
    "    -------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    if not only_dataframe:\n",
    "    \n",
    "        # get only top N most retweeted 'column' values to include in the heatmap\n",
    "        if top_n:        \n",
    "            top_column_values = df_rphs.sort_values(by='retweets_count', ascending=False)[:top_n][column].unique()\n",
    "            df = df[df.index.isin(top_column_values)]\n",
    "\n",
    "        # sort heatmap rows by relative_polarity values\n",
    "        df = df.sort_values('relative_polarity')\n",
    "        relative_polarities = df['relative_polarity'].map('{:,.2f}'.format).astype('str').to_list()\n",
    "        \n",
    "        # drop relative_polarity to not include in the heatmap\n",
    "        df = df.drop(columns=['relative_polarity'])\n",
    "        df = df.fillna(0.0)        \n",
    "            \n",
    "        # get a print friendly datatable\n",
    "        row_indexes = list(range(1,len(df.index)+1))\n",
    "        row_values = df.index        \n",
    "        df_heatmap_table = pd.DataFrame({'ID': row_indexes, y_label_left: row_values, 'RP(H)': relative_polarities})\n",
    "        \n",
    "        # create a sequential numeric 'id' for heatmap rows\n",
    "        if numeric_index:            \n",
    "            df['id'] = row_indexes\n",
    "            df = df.set_index('id')\n",
    "\n",
    "        plt.subplots(figsize=(2,round(top_n/3.5)))\n",
    "        ax = sns.heatmap(df, annot=False, linewidths=.1, robust=True, cmap='YlOrBr', vmin=0, vmax=vmax, cbar=False, square=True)\n",
    "        ax.set_title(title or '')\n",
    "        ax.set_xlabel(x_label or 'User P(H)')\n",
    "        ax.set_ylabel(y_label_left or '')\n",
    "        #ax.collections[0].colorbar.set_label(cbar_label or 'Retweet density')\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation = 0)\n",
    "\n",
    "        # maintain only 5 tick labels to simplify\n",
    "        for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "            if n not in [0, 5, 10, 15, 20]:\n",
    "                label.set_visible(False)\n",
    "\n",
    "        # add right y axis\n",
    "        ax2 = ax.twinx() # share x-axis\n",
    "        ax2.set_ylabel(y_label_right or '')\n",
    "        ax2.tick_params(right=True, pad=6)\n",
    "        ax2.set_aspect('auto', share=True, )\n",
    "        ax2.set_ylim((top_n, 0))\n",
    "        ax2.set_yticks(ax.get_yticks())\n",
    "        ax2.set_yticklabels(relative_polarities)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['bottom'].set_visible(False)\n",
    "        ax2.spines['left'].set_visible(False)\n",
    "\n",
    "        fig = ax.get_figure()\n",
    "        fig.set_size_inches(2, round(top_n/3.5))\n",
    "\n",
    "    return df_rphs, df_heatmap_table, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "df, df_heatmap, fig = relative_polarity_heatmap(\n",
    "    df=df_retweeted_urls, column='topic_words', y_label_left='Tópico', \n",
    "    y_label_right='Polaridade do tópico', x_label='Polaridade dos usuários',\n",
    "    top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "0c9dfea1575e8b44ff0615653062e3f77db49c736187dedf2087539b29eac2fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
